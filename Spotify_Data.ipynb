{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRKSRkmHp5n6"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "# Analyzing our Spotify Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9arbL3Vap_QC"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJDVBEUtqDFJ"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "### **Connecting to Drive**\n",
    "\n",
    "I use this code flow for all my normal projects. Firstly it primts a message for what enviornment is being used than it stores the directories as variables for further use. In colab since I use that for other subjects as well I have partitioned it accordingly but for my local drive I like to keep it simple. I know I have already created base, data, and archive folders but for output I will run the code below to create it if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Enf92hY6p3QU",
    "outputId": "0cd93998-3cea-4279-8b3f-a5e21c3668d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Running on Colab\n",
      "Base Folder is C:\\Users\\Abdul Rauf Maroof\\OneDrive\\Documents\\MSBA\n",
      "Data Folder is C:\\Users\\Abdul Rauf Maroof\\OneDrive\\Documents\\MSBA\\data_sets\n",
      "Archive Folder is C:\\Users\\Abdul Rauf Maroof\\OneDrive\\Documents\\MSBA\\archive\n",
      "Output Folder is C:\\Users\\Abdul Rauf Maroof\\OneDrive\\Documents\\MSBA\\notebooks\\spotify_project\\output\n",
      "The path to the custom functions is C:/Users/Abdul Rauf Maroof/OneDrive/Documents/MSBA/notebooks/spotify_project/custom_functions\n",
      "The working directory is c:\\Users\\Abdul Rauf Maroof\\OneDrive\\Documents\\MSBA\\notebooks\\spotify_project\n"
     ]
    }
   ],
   "source": [
    "# Use for normal projects\n",
    "# In colab since I use that for other subjects as well I have partitioned it accordingly \n",
    "# But for my local drive I like to keep it simple\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "  print('Running on Colab')\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive') \n",
    "  %pip install swifter -qq\n",
    "  %pip install spotipy --upgrade -qq\n",
    "  base_folder = Path('/content/drive/MyDrive/colab_notebooks/')\n",
    "  subject = 'aml'\n",
    "  data = base_folder/subject/'data/'\n",
    "  archive = base_folder/subject/'archive/'\n",
    "  output = base_folder/subject/'output'\n",
    "  if not Path(base_folder/subject/'output').exists():\n",
    "    os.makedirs(output,exist_ok=True)\n",
    "  print(f'Base Folder is {base_folder}')\n",
    "  print(f'Data Folder is {data}')\n",
    "  print(f'Archive Folder is {archive}')\n",
    "  print(f'Output Folder is {output}')\n",
    "else:\n",
    "  print('Not Running on Colab')\n",
    "  # Add the path to the custom-functions directory in the local file system to sys.path\n",
    "  sys.path.append('C:/Users/Abdul Rauf Maroof/OneDrive/Documents/MSBA/notebooks/spotify_project/custom_functions')\n",
    "  base_folder = Path('C:/Users/Abdul Rauf Maroof/OneDrive/Documents/MSBA')\n",
    "  data = base_folder/'data_sets/'\n",
    "  archive = base_folder/'archive/'\n",
    "  output = base_folder/'notebooks/spotify_project'/'output'\n",
    "  if not (base_folder/'notebooks/spotify_project'/'output').exists():\n",
    "    os.makedirs(output,exist_ok=True)\n",
    "  print(f'Base Folder is {base_folder}')\n",
    "  print(f'Data Folder is {data}')\n",
    "  print(f'Archive Folder is {archive}')\n",
    "  print(f'Output Folder is {output}')\n",
    "  print(f'The path to the custom functions is {sys.path[-1]}')\n",
    "  print(f'The working directory is {os.getcwd()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ox6RyWAvlf3"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "### Import libraries\n",
    "\n",
    "For the purpose of this project I am using the following libraries:\n",
    "\n",
    "1. Pandas: Pandas is a popular Python library for data manipulation and analysis. It provides tools for working with tabular data, including data structures for efficient data storage and retrieval, functions for data cleaning and transformation, and methods for summarizing and visualizing data.\n",
    "\n",
    "2. Numpy: Numpy is a fundamental Python library for scientific computing that provides support for large, multi-dimensional arrays and matrices, as well as a wide range of mathematical functions for working with these arrays. It also provides tools for linear algebra, Fourier analysis, and random number generation.\n",
    "\n",
    "3. Swifter: Swifter is a library that enables faster processing of Pandas DataFrames by utilizing parallel processing with Dask or Ray. It provides a simple API that allows users to apply Pandas functions to large datasets in parallel.\n",
    "\n",
    "4. Datetime: Datetime is a Python library that provides classes for working with dates, times, and time intervals. It includes functions for parsing and formatting dates and times, performing arithmetic with dates and times, and handling time zone information.\n",
    "\n",
    "5. Time: Time is a Python library that provides functions for working with time-related data, including measuring time intervals, sleeping for a specified duration, and retrieving the current time.\n",
    "\n",
    "6. Zipfile: Zipfile is a Python library for working with ZIP archives, which are collections of one or more files that have been compressed and packaged together. The Zipfile library provides tools for creating, reading, and modifying ZIP archives, as well as extracting files from archives.\n",
    "\n",
    "7. Json: JSON is a data interchange format that is widely used in web applications and APIs. The json library in Python provides functions for encoding and decoding JSON data, allowing Python objects to be serialized and deserialized into JSON strings.\n",
    "\n",
    "8. Spotipy: Spotipy is a Python library for working with the Spotify Web API. It provides tools for authenticating with the Spotify API, as well as methods for retrieving information about artists, albums, tracks, playlists, and users.\n",
    "\n",
    "9. Requests: Requests is a popular Python library for making HTTP requests. It provides a simple and easy-to-use API for sending HTTP requests and handling responses, including support for authentication, cookies, and custom headers.\n",
    "\n",
    "10. Seaborn: Seaborn is a Python data visualization library that is built on top of Matplotlib. It provides a high-level interface for creating a wide range of statistical graphics, including heatmaps, scatter plots, bar plots, line plots, and more. Seaborn includes a number of built-in themes and color palettes that make it easy to create aesthetically pleasing visualizations. It also provides tools for visualizing statistical relationships in data, such as linear regression, and for creating complex multi-panel figures. Seaborn is commonly used in data science and machine learning applications for exploratory data analysis and presentation of results.\n",
    "\n",
    "11. Matplotlib: Matplotlib is a Python library that is commonly used for creating high-quality visualizations such as graphs, plots, charts, and histograms. It is an open-source library that allows users to create static, animated, and interactive visualizations in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3bdUVIM6qb4k"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np   # For numerical operations\n",
    "import swifter # speed up apply from pandas\n",
    "from datetime import datetime, timedelta # to work with datetime and perform operations on it \n",
    "import time # to work with time \n",
    "\n",
    "# Import zipfile to extract data\n",
    "# Import JSON to read JSON file\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "# to connect to spotify api and retrieve data\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyOAuth, SpotifyClientCredentials\n",
    "import requests\n",
    "\n",
    "import seaborn as sns # for data visualization\n",
    "import matplotlib.pyplot as plt # for data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "### Define Functions to use\n",
    "\n",
    "I created some functions to make data extraction and processing easier. These functions helped me to automate a wide array of tasks by making it easier to process and alter datasets as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datetime_from_utc_to_local(utc_datetime):\n",
    "    \"\"\"\n",
    "    Converts a datetime value in UTC timezone to the local timezone.\n",
    "\n",
    "    Args:\n",
    "        utc_datetime (datetime.datetime): The datetime value to be converted from UTC to local timezone.\n",
    "\n",
    "    Returns:\n",
    "        datetime.datetime: The converted datetime value in local timezone.\n",
    "\n",
    "    Example:\n",
    "        >>> datetime_from_utc_to_local(datetime.datetime(2023, 3, 3, 12, 0, 0))\n",
    "        datetime.datetime(2023, 3, 3, 6, 0)\n",
    "\n",
    "    Note:\n",
    "        This function assumes that the system timezone is the local timezone. If the system timezone is not the local timezone,\n",
    "        you may need to modify the function accordingly to handle the correct timezone offset.\n",
    "    \"\"\"\n",
    "    now_timestamp = time.time()\n",
    "    offset = datetime.fromtimestamp(now_timestamp) - datetime.utcfromtimestamp(now_timestamp)\n",
    "    return utc_datetime + offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(text: str, directory: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extracts data from JSON files in a given directory that contain the specified text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to search for in the filename of the JSON files.\n",
    "        directory (str): The directory where the JSON files are stored.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the concatenated data from all matching JSON files.\n",
    "\n",
    "    Example:\n",
    "        >>> extract_data('2022', '/path/to/data/')\n",
    "        extracting data from streaming_data_2022.json\n",
    "        extracting data from playlist_data_2022.json\n",
    "        <pd.DataFrame>\n",
    "\n",
    "    Note:\n",
    "        This function assumes that the JSON files have a '.json' file extension and that the DataFrame can be concatenated\n",
    "        using the `pd.concat()` function. You may need to modify the function to handle different file extensions or\n",
    "        different ways of merging the data.\n",
    "    \"\"\"\n",
    "    dataframe = pd.DataFrame()\n",
    "    for entry in Path(directory).iterdir():\n",
    "        if 'json' in entry.name and text in entry.name:\n",
    "            print(f'extracting data from {entry.name}')\n",
    "            dataframe = pd.concat([dataframe, pd.read_json(entry)], axis=0, ignore_index=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets dataframe last 50 before a time period\n",
    "def recently_played(sp, limit=50, after=None):\n",
    "    \"\"\"\n",
    "    Returns a pandas DataFrame containing information about the user's recently played tracks.\n",
    "\n",
    "    Parameters:\n",
    "    sp (spotipy.Spotify): an authenticated Spotipy client object\n",
    "    limit (int, optional): the maximum number of results to return (default 50)\n",
    "    after (datetime, optional): a datetime object specifying the earliest time to include in the results\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: a DataFrame containing the following columns:\n",
    "        - played_at: a datetime object representing the time the track was played\n",
    "        - end_time: a datetime object representing the time the track finished playing\n",
    "        - ms_played: an integer representing the duration of the track in milliseconds\n",
    "        - track_name: a string representing the name of the track\n",
    "        - artist_name: a string representing the name of the track's artist\n",
    "        - album_name: a string representing the name of the track's album\n",
    "        - track_id: a string representing the ID of the track\n",
    "    \"\"\"\n",
    "    if after:\n",
    "        # convert the timestamp to the ISO 8601 format expected by the API\n",
    "        after = after.isoformat(timespec='milliseconds')\n",
    "    recent_tracks = []\n",
    "    results = sp.current_user_recently_played(limit=limit, after=after)\n",
    "    for item in results['items']:\n",
    "        track = item['track']\n",
    "        played_at = datetime.strptime(item['played_at'], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        end_time = played_at + timedelta(milliseconds=track['duration_ms'])\n",
    "        ms_played = track['duration_ms']\n",
    "        recent_tracks.append({\n",
    "            'played_at': played_at,\n",
    "            'end_time': end_time,\n",
    "            'ms_played': ms_played,\n",
    "            'track_name': track['name'],\n",
    "            'artist_name': track['artists'][0]['name'],\n",
    "            'album_name': track['album']['name'],\n",
    "            'track_id': track['id']\n",
    "        })\n",
    "    return pd.DataFrame(recent_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_and_artist_ids(tracks):\n",
    "    \"\"\"\n",
    "    Returns a pandas DataFrame containing information about the tracks and artists in the given list.\n",
    "\n",
    "    Parameters:\n",
    "    tracks (list): a list of tuples containing the track name and artist name\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: a DataFrame containing the following columns:\n",
    "        - id: a string representing the ID of the track\n",
    "        - track_uri: a string representing the URI of the track\n",
    "        - track_name: a string representing the name of the track\n",
    "        - artist_id: a string representing the ID of the track's artist\n",
    "        - artist_name: a string representing the name of the track's artist\n",
    "        - artist_uri: a string representing the URI of the track's artist\n",
    "        - album_id: a string representing the ID of the track's album\n",
    "        - album_name: a string representing the name of the track's album\n",
    "        - album_uri: a string representing the URI of the track's album\n",
    "\n",
    "    Example:\n",
    "    >>> get_track_and_artist_ids([('The Less I Know the Better', 'Tame Impala')])\n",
    "    \"\"\"\n",
    "    track_ids = []\n",
    "    for track in tracks:\n",
    "        name, artist = track\n",
    "        results = sp.search(q='track:' + name + ' artist:' + artist, type='track', limit=50)\n",
    "        items = results['tracks']['items']\n",
    "        if items:\n",
    "            track_id = items[0]['id']\n",
    "            track_uri = items[0]['uri']\n",
    "            artist_id = items[0]['artists'][0]['id']\n",
    "            artist_uri = items[0]['artists'][0]['uri']\n",
    "            album_id = items[0]['album']['id']\n",
    "            album_name = items[0]['album']['name']\n",
    "            album_uri = items[0]['album']['uri']\n",
    "            track_ids.append((track_id, track_uri ,name, artist_id, artist, artist_uri, album_id, album_name, album_uri))\n",
    "        else:\n",
    "            track_ids.append((None, name, artist))\n",
    "    return pd.DataFrame(track_ids, columns=['id', 'track_uri','track_name', 'artist_id', 'artist_name', 'artist_uri', 'album_id', 'album_name', 'album_uri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_of_day(datetime_column: str, df):\n",
    "   \"\"\"\n",
    "   Categorizes the time of day for each datetime value in the specified column of a given DataFrame.\n",
    "\n",
    "   Args:\n",
    "      datetime_column (str): The name of the column containing datetime values in the DataFrame.\n",
    "      df (pandas.DataFrame): The DataFrame to extract datetime values from. Default is streaming_data.\n",
    "\n",
    "   Returns:\n",
    "      pandas.Categorical: A categorical object containing the time of day for each datetime value in the specified column.\n",
    "      The categories are 'morning', 'afternoon', 'evening' and 'night', ordered chronologically.\n",
    "\n",
    "   Example:\n",
    "      >>> time_of_day('datetime', df=my_data)\n",
    "      [morning, afternoon, night, ...]\n",
    "      Categories (4, object): [morning < afternoon < evening < night]\n",
    "   \"\"\"\n",
    "   time_of_day = []\n",
    "   times = df[datetime_column].dt.hour\n",
    "   for time in times:\n",
    "         if time < 6:\n",
    "            time_of_day.append('night')\n",
    "         elif time < 12:\n",
    "            time_of_day.append('morning')\n",
    "         elif time < 18:\n",
    "            time_of_day.append('afternoon')\n",
    "         else:\n",
    "            time_of_day.append('evening')\n",
    "   return pd.Categorical(time_of_day, categories=['morning', 'afternoon', 'evening', 'night'], ordered=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_of_week(datetime_column: str, df):\n",
    "  \"\"\"\n",
    "  Extracts the day of the week from each datetime value in the specified column of a given DataFrame.\n",
    "\n",
    "  Args:\n",
    "    datetime_column (str): The name of the column containing datetime values in the DataFrame.\n",
    "    df (pandas.DataFrame): The DataFrame to extract datetime values from. Default is streaming_data.\n",
    "\n",
    "  Returns:\n",
    "    pandas.Categorical: A categorical object containing the day of the week for each datetime value in the specified column.\n",
    "    The categories are 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', and 'Sunday', ordered chronologically.\n",
    "\n",
    "  Example:\n",
    "    >>> day_of_week('datetime', df=my_data)\n",
    "    [Monday, Tuesday, Wednesday, ...]\n",
    "    Categories (7, object): [Monday < Tuesday < Wednesday < Thursday < Friday < Saturday < Sunday]\n",
    "  \"\"\"\n",
    "  day_of_week = [i.strftime('%A') for i in df[datetime_column]]\n",
    "  day_of_week = pd.Categorical(day_of_week, categories=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],ordered=True)\n",
    "  return day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month(datetime_column: str, df):\n",
    "  \"\"\"\n",
    "  Extracts the day of the week from each datetime value in the specified column of a given DataFrame.\n",
    "\n",
    "  Args:\n",
    "    datetime_column (str): The name of the column containing datetime values in the DataFrame.\n",
    "    df (pandas.DataFrame): The DataFrame to extract datetime values from. Default is streaming_data.\n",
    "\n",
    "  Returns:\n",
    "    pandas.Categorical: A categorical object containing the day of the week for each datetime value in the specified column.\n",
    "    The categories are 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', and 'Sunday', ordered chronologically.\n",
    "\n",
    "  Example:\n",
    "    >>> day_of_week('datetime', df=my_data)\n",
    "    [Monday, Tuesday, Wednesday, ...]\n",
    "    Categories (7, object): [Monday < Tuesday < Wednesday < Thursday < Friday < Saturday < Sunday]\n",
    "  \"\"\"\n",
    "  month = [i.strftime('%B') for i in df[datetime_column]]\n",
    "  month = pd.Categorical(month, categories=['January','February','March','April','May','June','July','August','September','October','November','December'],ordered=True)\n",
    "  return month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_audio_features(tracks):\n",
    "    \"\"\"\n",
    "    Returns a pandas DataFrame containing information about the tracks, artists, and audio features in the given list.\n",
    "\n",
    "    Parameters:\n",
    "    tracks (list): a list of tuples containing the track name and artist name\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: a DataFrame containing the following columns:\n",
    "        - id: a string representing the ID of the track\n",
    "        - track_uri: a string representing the URI of the track\n",
    "        - track_name: a string representing the name of the track\n",
    "        - acousticness: a float representing the acousticness of the track\n",
    "        - danceability: a float representing the danceability of the track\n",
    "        - energy: a float representing the energy of the track\n",
    "        - instrumentalness: a float representing the instrumentalness of the track\n",
    "        - liveness: a float representing the liveness of the track\n",
    "        - loudness: a float representing the loudness of the track\n",
    "        - speechiness: a float representing the speechiness of the track\n",
    "        - tempo: a float representing the tempo of the track\n",
    "        - valence: a float representing the valence of the track\n",
    "        - sections: a list of dictionaries containing information about the track's sections\n",
    "        - segments: a list of dictionaries containing information about the track's segments\n",
    "\n",
    "    Example:\n",
    "    >>> get_track_info([('The Less I Know the Better', 'Tame Impala')])\n",
    "    \"\"\"\n",
    "    track_info = []\n",
    "    for track in tracks:\n",
    "        name, artist = track\n",
    "        results = sp.search(q='track:' + name + ' artist:' + artist, type='track')\n",
    "        items = results['tracks']['items']\n",
    "        if items:\n",
    "            track_id = items[0]['id']\n",
    "            track_uri = items[0]['uri']\n",
    "            artist_id = items[0]['artists'][0]['id']\n",
    "            artist_uri = items[0]['artists'][0]['uri']\n",
    "            features = sp.audio_features(track_uri)[0]\n",
    "            track_info.append((track_id, track_uri, name, artist_id, artist, artist_uri,\n",
    "                               features['acousticness'], features['danceability'], features['energy'],\n",
    "                               features['instrumentalness'], features['liveness'], features['loudness'],\n",
    "                               features['speechiness'], features['tempo'], features['valence']))\n",
    "        else:\n",
    "            track_info.append((None, name, artist))\n",
    "    return pd.DataFrame(track_info, columns=['id', 'track_uri', 'track_name', 'artist_id','artist_name','artist_uri','acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo','valence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_genres(tracks):\n",
    "    \"\"\"\n",
    "    Returns a pandas DataFrame containing information about the tracks, artists, and audio features in the given list.\n",
    "\n",
    "    Parameters:\n",
    "    tracks (list): a list of tuples containing the track name and artist name\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: a DataFrame containing the following columns:\n",
    "        - id: a string representing the ID of the track\n",
    "        - track_uri: a string representing the URI of the track\n",
    "        - track_name: a string representing the name of the track\n",
    "        - artist_id: a string representing the ID of the track's artist\n",
    "        - artist_name: a string representing the name of the track's artist\n",
    "        - artist_uri: a string representing the URI of the track's artist\n",
    "        - album_id: a string representing the ID of the track's album\n",
    "        - album_name: a string representing the name of the track's album\n",
    "        - album_uri: a string representing the URI of the track's album\n",
    "        - artist_genres: a list of strings representing the genres of the track's artist\n",
    "        - album_genres: a list of strings representing the genres of the track's album\n",
    "\n",
    "    Example:\n",
    "    >>> get_track_info([('The Less I Know the Better', 'Tame Impala')])\n",
    "    \"\"\"\n",
    "    track_info = []\n",
    "    for track in tracks:\n",
    "        name, artist = track\n",
    "        results = sp.search(q='track:' + name + ' artist:' + artist, type='track')\n",
    "        items = results['tracks']['items']\n",
    "        if len(items) > 0:\n",
    "            track_id = items[0]['id']\n",
    "            track_uri = items[0]['uri']\n",
    "            artist_id = items[0]['artists'][0]['id']\n",
    "            artist_uri = items[0]['artists'][0]['uri']\n",
    "            artist_genres = sp.artist(artist_id)['genres']\n",
    "            track_info.append((track_id, track_uri, name, artist_id, artist, artist_uri, artist_genres))\n",
    "        else:\n",
    "            track_info.append((None, name, artist))\n",
    "    return pd.DataFrame(track_info, columns=['id', 'track_uri', 'track_name', 'artist_id', 'artist_name', 'artist_uri','artist_genres'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gg-Y84oFi2wj"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "### Setting up API for data extraction\n",
    "\n",
    "I got most of my data from spotify however there were certain features that I wanted to add that were not available in the dataset such as genres, audio features etc. I also want to extract song ids and spotify's own unique resource identifier code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell is to update my json credentials file in case of changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data/'credentials.json') as f:\n",
    "#     credentials = json.load(f)\n",
    "\n",
    "# print(credentials)\n",
    "\n",
    "# with open(data/'credentials.json', 'w') as f:\n",
    "#     json.dump(credentials, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below allows us to access the api and draw data from it as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "id": "hPg6U3FFi5mF"
   },
   "outputs": [],
   "source": [
    "# Get credentials from Spotify for Developers\n",
    "with open(data/'credentials.json') as f:\n",
    "    cred = json.load(f)\n",
    "\n",
    "# define the read scope\n",
    "scope = \"user-library-read\"\n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyOAuth(client_id=\"3b6c24d8b63a40f891504976c1872909\",\n",
    "                                               client_secret=\"44da19a313634041a2f3e2e225680ca7\",\n",
    "                                               redirect_uri=cred['redirect_uri'],\n",
    "                                               scope=scope))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fGeIQ0ffEY3F"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhrpyvAxqRi4"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "### Unzip data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "N5A0hOhipwBE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air_quality_data.zip\n",
      "my_spotify_data.zip\n",
      "my_spotify_data_2.zip\n",
      "Spotify-20230303T164824Z-001.zip\n",
      "stock_data.zip\n"
     ]
    }
   ],
   "source": [
    "zips = [x for x in archive.iterdir() if 'zip' in x.name]\n",
    "for entry in archive.iterdir():\n",
    "  if 'zip' in entry.name:\n",
    "    print(entry.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cCkhqtVtpwBI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MyData/DuoNewFamily.json', 'MyData/FamilyPlan.json', 'MyData/Follow.json', 'MyData/Identifiers.json', 'MyData/Identity.json', 'MyData/Inferences.json', 'MyData/Marquee.json', 'MyData/Payments.json', 'MyData/Playlist1.json', 'MyData/SearchQueries.json', 'MyData/StreamingHistory0.json', 'MyData/StreamingHistory1.json', 'MyData/StreamingHistory2.json', 'MyData/StreamingHistory3.json', 'MyData/Userdata.json', 'MyData/YourLibrary.json', 'MyData/', 'MyData/Read_Me_First.pdf']\n",
      "\n",
      " Data already extracted to C:\\Users\\Abdul Rauf Maroof\\OneDrive\\Documents\\MSBA\\data_sets\n"
     ]
    }
   ],
   "source": [
    "file = zips[1]\n",
    "\n",
    "with zipfile.ZipFile(file,'r') as f:\n",
    "  print(f.namelist())\n",
    "  if not Path(data/'MyData').exists():\n",
    "    f.extractall(data)\n",
    "    print('\\n',f'Data was extracted to {data}')\n",
    "  else:\n",
    "    print('\\n',f'Data already extracted to {data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16cewOZYsWCT"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "### Create Pandas DataFrame from JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "Now I'll extract data from the json files as needed and process it for further analysis by adding columns to perform joins and creating secondary tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "id": "a2o7FIJTsbaH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuoNewFamily.json\n",
      "FamilyPlan.json\n",
      "Follow.json\n",
      "Identifiers.json\n",
      "Identity.json\n",
      "Inferences.json\n",
      "Marquee.json\n",
      "Payments.json\n",
      "Playlist1.json\n",
      "SearchQueries.json\n",
      "StreamingHistory0.json\n",
      "StreamingHistory1.json\n",
      "StreamingHistory2.json\n",
      "StreamingHistory3.json\n",
      "Userdata.json\n",
      "YourLibrary.json\n"
     ]
    }
   ],
   "source": [
    "# changing the direcotry to match the data\n",
    "spotify_data = data/'MyData'\n",
    "for entry in spotify_data.iterdir():\n",
    "  if 'json' in entry.name:\n",
    "    print(entry.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOHqROjt4d5O"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "The files that important for the purpose of our analysis are as follows:\n",
    "\n",
    "1. Streaming Data\n",
    "2. Playlists\n",
    "3. Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7u7U51VEaQTm"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "##### Streaming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "id": "54Q_uwWpu6Bz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting data from StreamingHistory0.json\n",
      "extracting data from StreamingHistory1.json\n",
      "extracting data from StreamingHistory2.json\n",
      "extracting data from StreamingHistory3.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endTime</th>\n",
       "      <th>artistName</th>\n",
       "      <th>trackName</th>\n",
       "      <th>msPlayed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-27 10:01</td>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>bellyache</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-27 10:01</td>\n",
       "      <td>Sam Smith</td>\n",
       "      <td>Like I Can</td>\n",
       "      <td>2130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-27 10:01</td>\n",
       "      <td>Ruth B.</td>\n",
       "      <td>Dandelions</td>\n",
       "      <td>4240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-27 10:03</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>The Hills</td>\n",
       "      <td>125510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-27 10:04</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>Call Out My Name</td>\n",
       "      <td>11760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            endTime     artistName         trackName  msPlayed\n",
       "0  2022-02-27 10:01  Billie Eilish         bellyache      1680\n",
       "1  2022-02-27 10:01      Sam Smith        Like I Can      2130\n",
       "2  2022-02-27 10:01        Ruth B.        Dandelions      4240\n",
       "3  2022-02-27 10:03     The Weeknd         The Hills    125510\n",
       "4  2022-02-27 10:04     The Weeknd  Call Out My Name     11760"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_data = extract_data('Streaming',spotify_data)\n",
    "streaming_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFXF93zjaM-j"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "##### Playlist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "id": "1DhqwG-R3u2K"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting data from Playlist1.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playlists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'name': 'Hozier’s Lullaby ', 'lastModifiedDat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'name': 'Mile High View', 'lastModifiedDate':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'name': 'Recent Favorites', 'lastModifiedDate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'name': 'Cyberpunk', 'lastModifiedDate': '202...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           playlists\n",
       "0  {'name': 'Hozier’s Lullaby ', 'lastModifiedDat...\n",
       "1  {'name': 'Mile High View', 'lastModifiedDate':...\n",
       "2  {'name': 'Recent Favorites', 'lastModifiedDate...\n",
       "3  {'name': 'Cyberpunk', 'lastModifiedDate': '202..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lastModifiedDate</th>\n",
       "      <th>items</th>\n",
       "      <th>description</th>\n",
       "      <th>numberOfFollowers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hozier’s Lullaby</td>\n",
       "      <td>2023-02-23</td>\n",
       "      <td>[{'track': {'trackName': 'NFWMB', 'artistName'...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mile High View</td>\n",
       "      <td>2023-02-03</td>\n",
       "      <td>[{'track': {'trackName': 'goosebumps', 'artist...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recent Favorites</td>\n",
       "      <td>2022-12-11</td>\n",
       "      <td>[{'track': {'trackName': 'Blood Upon the Snow'...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cyberpunk</td>\n",
       "      <td>2022-07-06</td>\n",
       "      <td>[{'track': {'trackName': 'Teenagers', 'artistN...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name lastModifiedDate  \\\n",
       "0  Hozier’s Lullaby        2023-02-23   \n",
       "1     Mile High View       2023-02-03   \n",
       "2   Recent Favorites       2022-12-11   \n",
       "3          Cyberpunk       2022-07-06   \n",
       "\n",
       "                                               items description  \\\n",
       "0  [{'track': {'trackName': 'NFWMB', 'artistName'...        None   \n",
       "1  [{'track': {'trackName': 'goosebumps', 'artist...        None   \n",
       "2  [{'track': {'trackName': 'Blood Upon the Snow'...        None   \n",
       "3  [{'track': {'trackName': 'Teenagers', 'artistN...        None   \n",
       "\n",
       "   numberOfFollowers  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extracting data from Playlist1.json\n",
    "playlist_df = extract_data('Playlist', spotify_data); display(playlist_df.head(4))\n",
    "print('\\n')\n",
    "# from the look of it seems that I further need to work on the playlist file to properly extract data\n",
    "playlist_dict = pd.DataFrame([row for row in playlist_df.playlists]); display(playlist_dict.head(4))\n",
    "print('\\n')\n",
    "# Create a breaking point because I want to keep a tabel of all my playlists\n",
    "# I will also drop the items column because it contains a list of all the songs in the playlist \n",
    "# and I will extract that data in a different way\n",
    "playlist_core_df = playlist_dict\n",
    "playlist_core_df.drop(['items'], axis=1, inplace=True)\n",
    "#change the lastModifiedDate column to datetime format\n",
    "playlist_core_df['lastModifiedDate'] = pd.to_datetime(playlist_core_df['lastModifiedDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "id": "8HYkjV_oafBL"
   },
   "outputs": [],
   "source": [
    "# firstly I have all the playlists I have now I will repeat the process to create a dataframe for each playlist \n",
    "# and combine that into one with each playlist\n",
    "playlist_dict = pd.DataFrame([row for row in playlist_df.playlists])\n",
    "for i, value in enumerate(playlist_dict['items']):\n",
    "  globals()[f'playlist_{i+1}'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {
    "id": "QGfnp-St1gs6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1227 entries, 0 to 1226\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   trackName      1227 non-null   object        \n",
      " 1   artistName     1227 non-null   object        \n",
      " 2   albumName      1227 non-null   object        \n",
      " 3   trackUri       1227 non-null   object        \n",
      " 4   playlist_name  1227 non-null   object        \n",
      " 5   episode        0 non-null      object        \n",
      " 6   localTrack     0 non-null      object        \n",
      " 7   addedDate      1227 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(7)\n",
      "memory usage: 76.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# This loop will build on the previous loop and create a dataframe for each playlist\n",
    "# which I will concatenate into one dataframe\n",
    "for i in range(1, 21):\n",
    "    df_name = f'playlist_{i}'\n",
    "    df = globals()[df_name]\n",
    "    df_1 = pd.DataFrame(df)\n",
    "    df_2 = pd.DataFrame([row for row in df_1['track']])\n",
    "    df_2['playlist_name'] = playlist_dict.iloc[i-1]['name']\n",
    "    globals()[f'playlist_df_{i}'] = df_2.join(df_1).drop('track', axis=1)\n",
    "\n",
    "playlist_contents_df = pd.concat([globals()[f'playlist_df_{i}'] for i in range(1, 21)], ignore_index=True)\n",
    "# change the addedDate column to datetime format\n",
    "playlist_contents_df['addedDate'] = pd.to_datetime(playlist_contents_df['addedDate'])\n",
    "\n",
    "#check the data types and drop the columns that are not needed\n",
    "playlist_contents_df.info()\n",
    "playlist_contents_df.drop(['episode', 'localTrack'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {
    "id": "Kph9wT8O8Lxy"
   },
   "outputs": [],
   "source": [
    "# change the addedDate column to datetime format\n",
    "playlist_contents_df['addedDate'] = pd.to_datetime(playlist_contents_df['addedDate'])\n",
    "\n",
    "# create a count dataframe to join with the playlists core table to get a count of the number of songs in each playlist\n",
    "count = pd.DataFrame(playlist_contents_df.groupby('playlist_name')['playlist_name'].value_counts()).reset_index(level=1, drop=True).rename(columns={'name':'count'})\n",
    "\n",
    "#finally join the count dataframe with the playlist core dataframe\n",
    "playlist_core_df = playlist_core_df.join(count, on='name', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep in mind it is better to run certain cells seperately to avoid errors\n",
    "playlist_core_df.rename(columns={'playlist_name':'count'}, inplace=True)\n",
    "playlist_core_df.rename(columns={'name':'playlist_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   playlist_name     20 non-null     object        \n",
      " 1   lastModifiedDate  20 non-null     datetime64[ns]\n",
      " 2   count             20 non-null     int64         \n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 608.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# I'll drop number of followers and description because they are not needed and are empty or insignificant\n",
    "playlist_core_df.drop(['description', 'numberOfFollowers'], axis=1, inplace=True)\n",
    "playlist_core_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pkNnfeewDCrX"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "#### Library Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "id": "PSCOpwNx_I0I"
   },
   "outputs": [],
   "source": [
    "# After some analysis I settled on these keys as important while the others were empty\n",
    "file_json = spotify_data / 'YourLibrary.json'\n",
    "required_keys = ['tracks', 'shows', 'artists']\n",
    "# Opening JSON file\n",
    "with open(file_json) as f:\n",
    "  \n",
    "    # returns JSON object as \n",
    "    # a dictionary\n",
    "    libraries = json.load(f)\n",
    "\n",
    "    # Iterating through the json keys\n",
    "    for key in libraries.keys():\n",
    "        if key in required_keys:\n",
    "            globals()[f\"library_{key}\"] = pd.DataFrame(libraries[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>track</th>\n",
       "      <th>uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalia Lacunza</td>\n",
       "      <td>Otras Alas</td>\n",
       "      <td>Olivia</td>\n",
       "      <td>spotify:track:0okyvelhnnloZWHv6DwgSM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nusrat Fateh Ali Khan</td>\n",
       "      <td>Shahen-Shah</td>\n",
       "      <td>Kali Kali Zulfon Ke Phande Nah Dalo</td>\n",
       "      <td>spotify:track:41p2AWpXt0QF4GFlsxVowq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marshmello</td>\n",
       "      <td>BIBA</td>\n",
       "      <td>BIBA</td>\n",
       "      <td>spotify:track:0GVBPuCT3pBrXCdY3Uiy5B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brothers + Company</td>\n",
       "      <td>Run</td>\n",
       "      <td>Take This Love</td>\n",
       "      <td>spotify:track:74ehQPUbiEVkUM0UdmkVzc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pomme</td>\n",
       "      <td>les failles</td>\n",
       "      <td>grandiose</td>\n",
       "      <td>spotify:track:3NakEPSaVKsqqimJW66xCc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist        album                                track  \\\n",
       "0        Natalia Lacunza   Otras Alas                               Olivia   \n",
       "1  Nusrat Fateh Ali Khan  Shahen-Shah  Kali Kali Zulfon Ke Phande Nah Dalo   \n",
       "2             Marshmello         BIBA                                 BIBA   \n",
       "3     Brothers + Company          Run                       Take This Love   \n",
       "4                  Pomme  les failles                            grandiose   \n",
       "\n",
       "                                    uri  \n",
       "0  spotify:track:0okyvelhnnloZWHv6DwgSM  \n",
       "1  spotify:track:41p2AWpXt0QF4GFlsxVowq  \n",
       "2  spotify:track:0GVBPuCT3pBrXCdY3Uiy5B  \n",
       "3  spotify:track:74ehQPUbiEVkUM0UdmkVzc  \n",
       "4  spotify:track:3NakEPSaVKsqqimJW66xCc  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali Sethi</td>\n",
       "      <td>spotify:artist:3NegWDGp038A3FIi3gSYzl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arctic Monkeys</td>\n",
       "      <td>spotify:artist:7Ln80lUS6He07XvHI8qqHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Camila Cabello</td>\n",
       "      <td>spotify:artist:4nDoRrQiYLoBzwC5BhVJzF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Childish Gambino</td>\n",
       "      <td>spotify:artist:73sIBHcqh3Z3NyqHKZ7FOL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>spotify:artist:4gzpq5DPGxSnKTe4SA8HAU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                                    uri\n",
       "0         Ali Sethi  spotify:artist:3NegWDGp038A3FIi3gSYzl\n",
       "1    Arctic Monkeys  spotify:artist:7Ln80lUS6He07XvHI8qqHH\n",
       "2    Camila Cabello  spotify:artist:4nDoRrQiYLoBzwC5BhVJzF\n",
       "3  Childish Gambino  spotify:artist:73sIBHcqh3Z3NyqHKZ7FOL\n",
       "4          Coldplay  spotify:artist:4gzpq5DPGxSnKTe4SA8HAU"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>publisher</th>\n",
       "      <th>uri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A History of the World in 100 Objects</td>\n",
       "      <td>BBC Radio 4</td>\n",
       "      <td>spotify:show:01J8pPwYAt3NEvAkkuDOSs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Archetypes</td>\n",
       "      <td>Archewell Audio</td>\n",
       "      <td>spotify:show:6UfyXZgVAUX1UzF8j5L72t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batman Unburied</td>\n",
       "      <td>Warner Bros. / Spotify Studios</td>\n",
       "      <td>spotify:show:3pUWoZ6fC2qA02D3X0CeMb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Batman: The Audio Adventures</td>\n",
       "      <td>HBO Max</td>\n",
       "      <td>spotify:show:6YOANXuJ8AAtB2bFilDm6g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chasing Life</td>\n",
       "      <td>CNN</td>\n",
       "      <td>spotify:show:3nKvLT48YbbRQoCYQ4ern1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name                        publisher  \\\n",
       "0  A History of the World in 100 Objects                      BBC Radio 4   \n",
       "1                             Archetypes                  Archewell Audio   \n",
       "2                        Batman Unburied  Warner Bros. / Spotify Studios    \n",
       "3           Batman: The Audio Adventures                          HBO Max   \n",
       "4                           Chasing Life                              CNN   \n",
       "\n",
       "                                   uri  \n",
       "0  spotify:show:01J8pPwYAt3NEvAkkuDOSs  \n",
       "1  spotify:show:6UfyXZgVAUX1UzF8j5L72t  \n",
       "2  spotify:show:3pUWoZ6fC2qA02D3X0CeMb  \n",
       "3  spotify:show:6YOANXuJ8AAtB2bFilDm6g  \n",
       "4  spotify:show:3nKvLT48YbbRQoCYQ4ern1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(library_tracks.head())\n",
    "display(library_artists.head())\n",
    "display(library_shows.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "### Retriving Data from the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "As previously mentioned there is data I need from the API and I will be using some custom functions to extract that. It is important to note that after the data has been extracted I have commented out the because I don not need to run these again and again rather the data is appropriately stored in the ```output folder ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from tracks has been loaded with total records:\n",
      "6152\n",
      "\n",
      "Data from audio_features has been loaded with total records:\n",
      "6152\n",
      "\n",
      "Data from genres has been loaded with total records:\n",
      "6152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This code block checks to see if the tracks.csv file exists and if it does it loads it\n",
    "# if it does not exist it prints a message to the user to run the search\n",
    "# I am creating the search list here that is used in to extract data function\n",
    "\n",
    "search  = list(set(zip(streaming_data['trackName'], streaming_data['artistName'])))\n",
    "if Path(output/'tracks.csv').exists():\n",
    "    tracks = pd.read_csv(output/'tracks.csv') \n",
    "    print(f\"Data from tracks has been loaded with total records:\\n{len(tracks)}\\n\")\n",
    "if Path(output/'audio_features.csv').exists():\n",
    "    audio_features = pd.read_csv(output/'audio_features.csv')\n",
    "    print(f\"Data from audio_features has been loaded with total records:\\n{len(audio_features)}\\n\")\n",
    "if Path(output/'genres.csv').exists():\n",
    "    genres = pd.read_csv(output/'genres.csv')\n",
    "    print(f\"Data from genres has been loaded with total records:\\n{len(genres)}\\n\")\n",
    "else:\n",
    "    print(f'Looks like you have not run the search yet, please run the search and try again\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "The code block below is to extract data from the API for the corresponding tracks so that I can collect more data such as audio features and genres correctly. I only need to run this once to collect the data I need hence I have now commented out this block "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(search), 50):\n",
    "#     print(f'Function running {i/50} times')\n",
    "#     tracks = pd.DataFrame()\n",
    "#     track_ids = get_track_and_artist_ids(search[i:i+50])\n",
    "#     tracks = tracks.append(track_ids)\n",
    "#     tracks.to_csv(output/'tracks.csv', mode='a', header=False)\n",
    "\n",
    "# tracks = pd.read_csv(output/'tracks.csv',  names=['id', 'track_uri','track_name', 'artist_id', 'artist_name', 'artist_uri', 'album_id', 'album_name', 'album_uri'])\n",
    "# tracks['key'] = tracks['track_name'] + ':'+ tracks['artist_name']\n",
    "# tracks.reset_index(drop=True,inplace=True)\n",
    "# tracks.to_csv(output/'tracks.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(search), 50):\n",
    "#     print(f'Function running {i/50} times')\n",
    "#     audio_features = pd.DataFrame()\n",
    "#     audio_feature_data = get_track_audio_features(search[i:i+50])\n",
    "#     audio_features = audio_features.append(audio_feature_data)\n",
    "#     audio_features.to_csv(output/'audio_features.csv', mode='a', header=False)\n",
    "\n",
    "# audio_features = pd.read_csv(output/'audio_features.csv',  names=['id', 'track_uri', 'track_name', 'artist_id','artist_name','artist_uri','acousticness', 'danceability', 'energy', 'instrumentalness', 'liveness', 'loudness', 'speechiness', 'tempo','valence'])\n",
    "# audio_features['key'] = audio_features['track_name'] + ':'+ audio_features['artist_name']\n",
    "# audio_features.reset_index(drop=True,inplace=True)\n",
    "# audio_features.to_csv(output/'audio_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0, len(search), 50):\n",
    "#     print(f'Function running {i/50} times')\n",
    "#     genres = pd.DataFrame()\n",
    "#     genres_data = get_track_genres(search[i:i+50])\n",
    "#     genres = genres.append(genres_data)\n",
    "#     genres.to_csv(output/'genres.csv', mode='a', header=False)\n",
    "\n",
    "# genres = pd.read_csv(output/'genres.csv',  names=['id', 'track_uri', 'track_name', 'artist_id', 'artist_name', 'artist_uri','genres_albums'])\n",
    "# genres['key'] = genres['track_name'] + ':'+ genres['artist_name']\n",
    "# genres.reset_index(drop=True,inplace=True)\n",
    "# genres.to_csv(output/'genres.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will finally store the unedited data in a folder called my_spotify_api_data\n",
    "# This is to ensure that I can always go back to the original data\n",
    "\n",
    "if (data/'my_spotify_api_data').exists():\n",
    "    tracks.to_csv(data/'my_spotify_api_data/tracks.csv', index=False)\n",
    "    audio_features.to_csv(data/'my_spotify_api_data/audio_features.csv', index=False)\n",
    "    genres.to_csv(data/'my_spotify_api_data/genres.csv', index=False)\n",
    "else:\n",
    "    os.makedirs(data/'my_spotify_api_data', exist_ok=True)\n",
    "    tracks.to_csv(data/'my_spotify_api_data/tracks.csv', index=False)\n",
    "    audio_features.to_csv(data/'my_spotify_api_data/audio_features.csv', index=False)\n",
    "    genres.to_csv(data/'my_spotify_api_data/genres.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "### Cleaning and processing API data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "Once I have extracted data from the api I can now begin to process and clean it for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6152 entries, 0 to 6151\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           5586 non-null   object\n",
      " 1   track_uri    6152 non-null   object\n",
      " 2   track_name   6152 non-null   object\n",
      " 3   artist_id    5586 non-null   object\n",
      " 4   artist_name  5586 non-null   object\n",
      " 5   artist_uri   5586 non-null   object\n",
      " 6   album_id     5586 non-null   object\n",
      " 7   album_name   5586 non-null   object\n",
      " 8   album_uri    5586 non-null   object\n",
      " 9   key          5586 non-null   object\n",
      "dtypes: object(10)\n",
      "memory usage: 480.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6152 entries, 0 to 6151\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                5586 non-null   object \n",
      " 1   track_uri         6152 non-null   object \n",
      " 2   track_name        6152 non-null   object \n",
      " 3   artist_id         5586 non-null   object \n",
      " 4   artist_name       5586 non-null   object \n",
      " 5   artist_uri        5586 non-null   object \n",
      " 6   acousticness      5586 non-null   float64\n",
      " 7   danceability      5586 non-null   float64\n",
      " 8   energy            5586 non-null   float64\n",
      " 9   instrumentalness  5586 non-null   float64\n",
      " 10  liveness          5586 non-null   float64\n",
      " 11  loudness          5586 non-null   float64\n",
      " 12  speechiness       5586 non-null   float64\n",
      " 13  tempo             5586 non-null   float64\n",
      " 14  valence           5586 non-null   float64\n",
      " 15  key               5586 non-null   object \n",
      "dtypes: float64(9), object(7)\n",
      "memory usage: 769.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6152 entries, 0 to 6151\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             5586 non-null   object\n",
      " 1   track_uri      6152 non-null   object\n",
      " 2   track_name     6152 non-null   object\n",
      " 3   artist_id      5586 non-null   object\n",
      " 4   artist_name    5586 non-null   object\n",
      " 5   artist_uri     5586 non-null   object\n",
      " 6   genres_albums  5586 non-null   object\n",
      " 7   key            5586 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 384.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check to make sure the data is loaded correctly\n",
    "display(tracks.info())\n",
    "print('\\n')\n",
    "display(audio_features.info())\n",
    "print('\\n')\n",
    "display(genres.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can see that 9.2% of the tracks were not identified\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# I now explore the tracks data to see how many tracks were correctly identified\n",
    "# I can see \n",
    "tracks['track_name'].count() == len(search)\n",
    "print(f\"I can see that {round((1 - (tracks['id'].count() / tracks['track_name'].count())) * 100,2)}% of the tracks were not identified\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have extracted the data for tracks that had no Id. Based on the name I can see that these are actually podcasts\n",
    "podcasts = tracks[tracks['id'].isna()].reset_index(drop=True)\n",
    "podcasts  = podcasts[['track_uri','track_name']].rename({'track_uri':'episode', 'track_name':'podcast'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interestingly there are some songs mixed into the podcasts but a majority of them are podcasts\n",
    "# So I will drop the songs and keep the podcasts\n",
    "podcasts.groupby('podcast').count().sort_values(by='episode', ascending=False).head(20)\n",
    "podcasts = podcasts[podcasts.groupby('podcast')['podcast'].transform('count') > 1]\n",
    "# check if podcast is actually an artist by cross referencing the artist table\n",
    "podcasts = podcasts[~podcasts['podcast'].isin(tracks['artist_name'])]\n",
    "podcasts.groupby('podcast').count().sort_values(by='episode', ascending=False).head(20)\n",
    "podcasts['key'] = podcasts['podcast'] + podcasts['episode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I will drop the podcasts from the tables because we can see that features for these are not available\n",
    "tracks = tracks[tracks['id'].notna()].reset_index(drop=True)\n",
    "audio_features = audio_features[audio_features['id'].notna()].reset_index(drop=True)\n",
    "genres = genres[genres['id'].notna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5586 entries, 0 to 5585\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           5586 non-null   object\n",
      " 1   track_uri    5586 non-null   object\n",
      " 2   track_name   5586 non-null   object\n",
      " 3   artist_id    5586 non-null   object\n",
      " 4   artist_name  5586 non-null   object\n",
      " 5   artist_uri   5586 non-null   object\n",
      " 6   album_id     5586 non-null   object\n",
      " 7   album_name   5586 non-null   object\n",
      " 8   album_uri    5586 non-null   object\n",
      " 9   key          5586 non-null   object\n",
      "dtypes: object(10)\n",
      "memory usage: 436.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5586 entries, 0 to 5585\n",
      "Data columns (total 16 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                5586 non-null   object \n",
      " 1   track_uri         5586 non-null   object \n",
      " 2   track_name        5586 non-null   object \n",
      " 3   artist_id         5586 non-null   object \n",
      " 4   artist_name       5586 non-null   object \n",
      " 5   artist_uri        5586 non-null   object \n",
      " 6   acousticness      5586 non-null   float64\n",
      " 7   danceability      5586 non-null   float64\n",
      " 8   energy            5586 non-null   float64\n",
      " 9   instrumentalness  5586 non-null   float64\n",
      " 10  liveness          5586 non-null   float64\n",
      " 11  loudness          5586 non-null   float64\n",
      " 12  speechiness       5586 non-null   float64\n",
      " 13  tempo             5586 non-null   float64\n",
      " 14  valence           5586 non-null   float64\n",
      " 15  key               5586 non-null   object \n",
      "dtypes: float64(9), object(7)\n",
      "memory usage: 698.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5586 entries, 0 to 5585\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   id             5586 non-null   object\n",
      " 1   track_uri      5586 non-null   object\n",
      " 2   track_name     5586 non-null   object\n",
      " 3   artist_id      5586 non-null   object\n",
      " 4   artist_name    5586 non-null   object\n",
      " 5   artist_uri     5586 non-null   object\n",
      " 6   genres_albums  5586 non-null   object\n",
      " 7   key            5586 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 349.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We finally check to make sure that the tables are consistent with each other\n",
    "display(tracks.info())\n",
    "print('\\n')\n",
    "display(audio_features.info())\n",
    "print('\\n')\n",
    "display(genres.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoyfECZ5SC1_"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "## EDA and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endTime</th>\n",
       "      <th>artistName</th>\n",
       "      <th>trackName</th>\n",
       "      <th>msPlayed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-27 04:01:00</td>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>bellyache</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-27 04:01:00</td>\n",
       "      <td>Sam Smith</td>\n",
       "      <td>Like I Can</td>\n",
       "      <td>2130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-27 04:01:00</td>\n",
       "      <td>Ruth B.</td>\n",
       "      <td>Dandelions</td>\n",
       "      <td>4240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-27 04:03:00</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>The Hills</td>\n",
       "      <td>125510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-27 04:04:00</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>Call Out My Name</td>\n",
       "      <td>11760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36115</th>\n",
       "      <td>2023-02-27 15:21:00</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>Circles</td>\n",
       "      <td>22801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36116</th>\n",
       "      <td>2023-02-27 15:21:00</td>\n",
       "      <td>Paul Anka</td>\n",
       "      <td>Put Your Head on My Shoulder</td>\n",
       "      <td>15418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36118</th>\n",
       "      <td>2023-02-27 15:21:00</td>\n",
       "      <td>Regard</td>\n",
       "      <td>Ride It</td>\n",
       "      <td>5387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36119</th>\n",
       "      <td>2023-02-27 15:22:00</td>\n",
       "      <td>Lana Del Rey</td>\n",
       "      <td>Fuck it I love you</td>\n",
       "      <td>3784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36120</th>\n",
       "      <td>2023-02-27 15:22:00</td>\n",
       "      <td>blackbear</td>\n",
       "      <td>hot girl bummer</td>\n",
       "      <td>43444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36121 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  endTime     artistName                     trackName  \\\n",
       "0     2022-02-27 04:01:00  Billie Eilish                     bellyache   \n",
       "1     2022-02-27 04:01:00      Sam Smith                    Like I Can   \n",
       "2     2022-02-27 04:01:00        Ruth B.                    Dandelions   \n",
       "3     2022-02-27 04:03:00     The Weeknd                     The Hills   \n",
       "4     2022-02-27 04:04:00     The Weeknd              Call Out My Name   \n",
       "...                   ...            ...                           ...   \n",
       "36115 2023-02-27 15:21:00    Post Malone                       Circles   \n",
       "36116 2023-02-27 15:21:00      Paul Anka  Put Your Head on My Shoulder   \n",
       "36118 2023-02-27 15:21:00         Regard                       Ride It   \n",
       "36119 2023-02-27 15:22:00   Lana Del Rey            Fuck it I love you   \n",
       "36120 2023-02-27 15:22:00      blackbear               hot girl bummer   \n",
       "\n",
       "       msPlayed  \n",
       "0          1680  \n",
       "1          2130  \n",
       "2          4240  \n",
       "3        125510  \n",
       "4         11760  \n",
       "...         ...  \n",
       "36115     22801  \n",
       "36116     15418  \n",
       "36118      5387  \n",
       "36119      3784  \n",
       "36120     43444  \n",
       "\n",
       "[36121 rows x 4 columns]"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_data['endTime'] = pd.to_datetime(streaming_data['endTime'])\n",
    "streaming_data['endTime'] = datetime_from_utc_to_local(streaming_data['endTime'])\n",
    "streaming_data.sort_values(by='endTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "id": "24n_LhKVSH5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36121 entries, 0 to 36120\n",
      "Data columns (total 7 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   endTime         36121 non-null  datetime64[ns]\n",
      " 1   artistName      36121 non-null  object        \n",
      " 2   trackName       36121 non-null  object        \n",
      " 3   msPlayed        36121 non-null  int64         \n",
      " 4   key             36121 non-null  object        \n",
      " 5   minutes_played  36121 non-null  float64       \n",
      " 6   seconds_played  36121 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(3)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "streaming_data['key'] = streaming_data['artistName']+':'+streaming_data['trackName']\n",
    "streaming_data['minutes_played'] = streaming_data['msPlayed'].swifter.apply(lambda x: (x / 60000)) # there are 60,000 ms in a minute\n",
    "streaming_data['seconds_played'] = streaming_data['msPlayed'].swifter.apply(lambda x: (x / 1000)) # there are 1000 ms in a second\n",
    "streaming_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_data['time_of_day'] = time_of_day('endTime',df=streaming_data)\n",
    "streaming_data['day_of_week'] = day_of_week('endTime',df=streaming_data)\n",
    "streaming_data['month'] = month('endTime',df=streaming_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackName</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_of_day</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>morning</th>\n",
       "      <td>6993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afternoon</th>\n",
       "      <td>12873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evening</th>\n",
       "      <td>9809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>night</th>\n",
       "      <td>6446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>36121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             trackName\n",
       "time_of_day           \n",
       "morning           6993\n",
       "afternoon        12873\n",
       "evening           9809\n",
       "night             6446\n",
       "All              36121"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(streaming_data, index='time_of_day', values='trackName', aggfunc='count',margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWLWnnlbEuT4"
   },
   "source": [
    "<font color=\"#1DB954\">\n",
    "\n",
    "## Save all files to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "id": "UwW7luzCFl16"
   },
   "outputs": [],
   "source": [
    "# Save streaming data\n",
    "streaming_data.to_csv(output/'streaming_data.csv',index=False)\n",
    "# Save playlist core data\n",
    "playlist_core_df.to_csv(output/'playlist_core_data.csv',index=False)\n",
    "# Save playlist contents\n",
    "playlist_contents_df.to_csv(output/'playlist_contents_data.csv',index=False)\n",
    "# Save library_artists\n",
    "library_artists.to_csv(output/'library_artists.csv',index=False)\n",
    "# Save library_shows\n",
    "library_shows.to_csv(output/'library_shows.csv',index=False)\n",
    "# Save library_tracks\n",
    "library_tracks.to_csv(output/'library_tracks.csv',index=False)\n",
    "# Save podcasts\n",
    "podcasts.to_csv(output/'podcasts.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "xJDVBEUtqDFJ",
    "8ox6RyWAvlf3",
    "7u7U51VEaQTm",
    "cFXF93zjaM-j",
    "pkNnfeewDCrX"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
